

本文用于汇总 Redis 内存相关问题！

----------

# 为什么Redis内存不宜过大

## 主库宕机

主库宕机容灾过程：在主库宕机的时候，最常见的容灾策略为“切主”。具体为从该集群剩余从库中选出一个从库并将其升级为主库，之后再将剩余从库挂载至其下成为其从库，最终恢复整个主从集群结构。

> ⚠️ 以上是一个完整的容灾过程，而代价最大的过程为**从库的重新挂载**，而非主库的切换。

这是因为 redis 无法像 mysql 、mongodb 那样基于同步的点位在主库发生变化后从新的主库继续同步数据。 在redis 集群中一旦从库换主，redis 的做法是将更换主库的从库清空，然后从新主库完整同步一份数据再进行续传。

整个从库重做流程是这样的：
- 主库 bgsave 自身数据到磁盘；
- 主库发送 rdb 文件到从库；
- 从库开始加载；
- 加载完毕后开始续传，同时开始提供服务；

很明显，在这个过程中 redis 的内存体积越大，则以上每一个步骤的时间都会被拉长，实际测试数据如下（在足够好的机器上）

内存体积 | 从库重做时间
--------|--------------
5G  | 4min
10G | 8min
20G | 18min
30G | 30min
50G | 60min

可以看到，当数据达到（占用内存）20G 的时候，一个从库的恢复时间已经被拉长到了将近 20 分钟，如果有 10个从库，那么如果依次恢复则共需 200 分钟，如果此时该从库承担着大量的读取请求，你能够忍受这么长的恢复时间吗？

看到这里你肯定会问：**为什么不能同时重做所有从库？**这是因为如果所有从库同时向主库请求 rdb 文件，那么主库的网卡则立即跑满，从而进入一个无法正常提供服务的状态，此时主库（可能会）又死了，将雪上加霜。

当然，我们可以批量恢复从库，例如两两一组（确保网卡不被跑满），那么全部从库的恢复时间也仅仅从 200 分钟降低到了 100 分钟，但这仍然是五十步笑百步；

另一个重要问题和上面的第四点有关，续传（的实现）可以理解为（基于）一个简化的 mongodb 的 oplog ，它是一个体积固定的内存空间，我们称之为“同步缓冲区”。

> 需要补充理论知识；

redis 主库的写入操作都会在该缓冲区中存放一份然后发送给从库，而如果在上文中 1, 2, 3 步耗时太久那么很可能这个同步缓冲区被重写，此时从库将无法找到对应的续传位置；因为，从库只能重做 1, 2, 3 步骤；

因为我们无法解决 1，2，3 步骤的耗时，因此该从库将进入无限次数的恶性循环：不停的向主库请求完整数据，结果对主库的网卡造成严重影响。

## 扩容问题

很多时候会出现流量的突发性增长，通常在找到原因之前，我们的应急做法就是**扩容**了。

而根据上面的表格，一个 20G 的 redis 扩容一个从库需要将近 20 分钟，而问题是业务能够容忍 20 分钟的业务停摆么？可能还没扩好业务就死翘翘了。

## 网络问题导致从库重做进而引发雪崩

该场景下的最大问题是：**主库与从库发生同步中断，与此同时主库仍然在接受写入请求**；一旦中断时间过长，同步缓冲区就很可能被复写（发生覆盖），进而导致从库的上一次同步位置丢失；在网络恢复后，虽然（此时）主库没有（继续）发生变化，但由于从库的同步位置已丢失，从库只能通过重做的方式确保与主库的一致，也就是之前提到的 1，2，3，4 步骤；如果此时主库内存体积过大，那么从库重做的速度就会很慢，而发送到从库的读请求就会受到严重影响；同时由于传输的 rdb 文件的体积过大，主库的网卡在相当长的一段时间内都会受到严重影响；

## 内存越大，触发持久化的操作阻塞主线程的时间越长

Redis 是单线程内存数据库，在 redis 需要执行耗时操作时，会 fork 一个新进程来做，比如 bgsave 或bgrewriteaof 。 虽然 fork 新进程时可共享的数据内容不需要复制，但会复制父进程空间中的内存页表，这个复制是由主线程来做的，会阻塞所有的读写操作，并且随着内存使用量越大耗时越长。例如：内存 20G 的 redis ，bgsave 复制内存页表耗时约为 750ms ，redis 主线程也会因为它阻塞 750ms ；


## 解决办法

解决办法就是极力减少内存的使用，一般情况下，做法如下：

### 设置过期时间
对具有时效性的 key 设置过期时间，通过 redis 自身的过期 key 清理策略来降低过期 key 对于内存的占用，同时也能够减少业务的麻烦，不需要定期清理了；

### 不存放垃圾到 redis 中
这虽然是废话，但也意味着很多人会犯这种错误；

###及时清理无用数据
例如一个 redis 承载了 3 个业务的数据，一段时间后有 2 个业务下线了，此时就应该把这两个业务的相关数据立刻清理掉；

### 尽量对数据进行压缩
例如一些长文本形式的数据，压缩能够大幅度降低内存占用；

### 关注内存增长并定位大容量 key
不管是 DBA 还是开发人员，只要用 redis 就必须关注内存；否则，你其实就是不称职的；常用方式是：分析 redis 实例中哪些 key 比较大，从而帮助业务快速定位异常 key（非预期增长的 key ，往往是问题之源）；

### pika
如果实在不想搞的那么累，那就把业务迁移到 360 新开源的 pika 上面，这样就不用太关注内存了，redis 内存太大引发的问题，那也都不是问题了（存在安利嫌疑）；

> ⚠️ Pika 主要解决的问题是：用户使用 Redis 的内存大小超过 50G、80G 等等这样的情况，此时会遇到
>> - 启动恢复时间长；
>> - 主多从代价大；
>> - 硬件成本贵；
>> - 缓冲区容易写满
> 
> 等问题，Pika 就是针对这些场景的一个解决方案，不能单纯的认为其优于 Redis 方案；


参考：《[为什么Redis内存不宜过大](https://mp.weixin.qq.com/s?__biz=MzA4NDExOTEyOA==&mid=2649779368&idx=4&sn=a8b5f0b6c399ed40938d30a7e6a6c63b&scene=1&srcid=0817sL4YElry4EEuyBFb2pCV&pass_ticket=3Q%2Fz25YbaVx9NmwDaGh%2F4swJn1%2BWROo8G7iEhwUp1JmGJDYvv79bpY0TWQqYJKQq#rd)》


----------



本文用于汇总 Redis 内存相关问题！

1. 为什么Redis内存不宜过大
2. 节约内存：Instagram的Redis实践
3. 360开源的类Redis存储系统:Pika
4. 同程旅游缓存系统设计:如何打造Redis时代的完美体系
5. 近千节点的Redis Cluster高可用集群案例:优酷蓝鲸优化实战

----------

# 为什么Redis内存不宜过大

## 主库宕机

主库宕机容灾过程：在主库宕机的时候，最常见的容灾策略为“切主”。具体为从该集群剩余从库中选出一个从库并将其升级为主库，之后再将剩余从库挂载至其下成为其从库，最终恢复整个主从集群结构。

> ⚠️ 以上是一个完整的容灾过程，而代价最大的过程为**从库的重新挂载**，而非主库的切换。

这是因为 redis 无法像 mysql 、mongodb 那样基于同步的点位在主库发生变化后从新的主库继续同步数据。 在redis 集群中一旦从库换主，redis 的做法是将更换主库的从库清空，然后从新主库完整同步一份数据再进行续传。

整个从库重做流程是这样的：
- 主库 bgsave 自身数据到磁盘；
- 主库发送 rdb 文件到从库；
- 从库开始加载；
- 加载完毕后开始续传，同时开始提供服务；

很明显，在这个过程中 redis 的内存体积越大，则以上每一个步骤的时间都会被拉长，实际测试数据如下（在足够好的机器上）

内存体积 | 从库重做时间
--------|--------------
5G  | 4min
10G | 8min
20G | 18min
30G | 30min
50G | 60min

可以看到，当数据达到（占用内存）20G 的时候，一个从库的恢复时间已经被拉长到了将近 20 分钟，如果有 10个从库，那么如果依次恢复则共需 200 分钟，如果此时该从库承担着大量的读取请求，你能够忍受这么长的恢复时间吗？

看到这里你肯定会问：**为什么不能同时重做所有从库？**这是因为如果所有从库同时向主库请求 rdb 文件，那么主库的网卡则立即跑满，从而进入一个无法正常提供服务的状态，此时主库（可能会）又死了，将雪上加霜。

当然，我们可以批量恢复从库，例如两两一组（确保网卡不被跑满），那么全部从库的恢复时间也仅仅从 200 分钟降低到了 100 分钟，但这仍然是五十步笑百步；

另一个重要问题和上面的第四点有关，续传（的实现）可以理解为（基于）一个简化的 mongodb 的 oplog ，它是一个体积固定的内存空间，我们称之为“同步缓冲区”。

> 需要补充理论知识；

redis 主库的写入操作都会在该缓冲区中存放一份然后发送给从库，而如果在上文中 1, 2, 3 步耗时太久那么很可能这个同步缓冲区被重写，此时从库将无法找到对应的续传位置；因为，从库只能重做 1, 2, 3 步骤；

因为我们无法解决 1，2，3 步骤的耗时，因此该从库将进入无限次数的恶性循环：不停的向主库请求完整数据，结果对主库的网卡造成严重影响。

## 扩容问题

很多时候会出现流量的突发性增长，通常在找到原因之前，我们的应急做法就是**扩容**了。

而根据上面的表格，一个 20G 的 redis 扩容一个从库需要将近 20 分钟，而问题是业务能够容忍 20 分钟的业务停摆么？可能还没扩好业务就死翘翘了。

## 网络问题导致从库重做进而引发雪崩

该场景下的最大问题是：**主库与从库发生同步中断，与此同时主库仍然在接受写入请求**；一旦中断时间过长，同步缓冲区就很可能被复写（发生覆盖），进而导致从库的上一次同步位置丢失；在网络恢复后，虽然（此时）主库没有（继续）发生变化，但由于从库的同步位置已丢失，从库只能通过重做的方式确保与主库的一致，也就是之前提到的 1，2，3，4 步骤；如果此时主库内存体积过大，那么从库重做的速度就会很慢，而发送到从库的读请求就会受到严重影响；同时由于传输的 rdb 文件的体积过大，主库的网卡在相当长的一段时间内都会受到严重影响；

## 内存越大，触发持久化的操作阻塞主线程的时间越长

Redis 是单线程内存数据库，在 redis 需要执行耗时操作时，会 fork 一个新进程来做，比如 bgsave 或bgrewriteaof 。 虽然 fork 新进程时可共享的数据内容不需要复制，但会复制父进程空间中的内存页表，这个复制是由主线程来做的，会阻塞所有的读写操作，并且随着内存使用量越大耗时越长。例如：内存 20G 的 redis ，bgsave 复制内存页表耗时约为 750ms ，redis 主线程也会因为它阻塞 750ms ；


## 解决办法

解决办法就是极力减少内存的使用，一般情况下，做法如下：

### 设置过期时间
对具有时效性的 key 设置过期时间，通过 redis 自身的过期 key 清理策略来降低过期 key 对于内存的占用，同时也能够减少业务的麻烦，不需要定期清理了；

### 不存放垃圾到 redis 中
这虽然是废话，但也意味着很多人会犯这种错误；

###及时清理无用数据
例如一个 redis 承载了 3 个业务的数据，一段时间后有 2 个业务下线了，此时就应该把这两个业务的相关数据立刻清理掉；

### 尽量对数据进行压缩
例如一些长文本形式的数据，压缩能够大幅度降低内存占用；

### 关注内存增长并定位大容量 key
不管是 DBA 还是开发人员，只要用 redis 就必须关注内存；否则，你其实就是不称职的；常用方式是：分析 redis 实例中哪些 key 比较大，从而帮助业务快速定位异常 key（非预期增长的 key ，往往是问题之源）；

### pika
如果实在不想搞的那么累，那就把业务迁移到 360 新开源的 pika 上面，这样就不用太关注内存了，redis 内存太大引发的问题，那也都不是问题了（存在安利嫌疑）；

> ⚠️ Pika 主要解决的问题是：用户使用 Redis 的内存大小超过 50G、80G 等等这样的情况，此时会遇到
>> - 启动恢复时间长；
>> - 主多从代价大；
>> - 硬件成本贵；
>> - 缓冲区容易写满
> 
> 等问题，Pika 就是针对这些场景的一个解决方案，不能单纯的认为其优于 Redis 方案；


原文：《[为什么Redis内存不宜过大](https://mp.weixin.qq.com/s?__biz=MzA4NDExOTEyOA==&mid=2649779368&idx=4&sn=a8b5f0b6c399ed40938d30a7e6a6c63b&scene=1&srcid=0817sL4YElry4EEuyBFb2pCV&pass_ticket=3Q%2Fz25YbaVx9NmwDaGh%2F4swJn1%2BWROo8G7iEhwUp1JmGJDYvv79bpY0TWQqYJKQq#rd)》


----------

# 节约内存：Instagram的Redis实践

条件：基于 Redis 的 String 结构来做 key-value 存储；

关键点：
- 数据量预估＋Redis 内存容量计算；
- Redis 中的 key 不会进行字符串到数字的转换（即使其为纯数字）； 

条件：基于 Redis 的 Hash 结构来做 key-value 存储；

关键点：
- 通过 hash-zipmap-max-entries 参数控制压缩判定阈值；

> 开发者实验：将 hash-zipmap-max-entries 设置为 1000 时性能比较好，超过 1000 后 HSET 命令就会导致 CPU消耗变得非常大；



原文：《[节约内存：Instagram的Redis实践](http://mp.weixin.qq.com/s?__biz=MzA5Njg1OTI5Mg==&mid=2651025383&idx=1&sn=4a3786b6b93fa90b2f6409ebb6b3504f&scene=1&srcid=0819DOyloixa4YRZxuA0NKsb#rd)》

----------


# 360开源的类Redis存储系统:Pika


## 使用场景

Pika 主要解决的是用户使用 Redis 的内存大小超过 50G、80G 等等这样的情况，会遇到启动恢复时间长，一主多从代价大，硬件成本贵，缓冲区容易写满等问题。Pika 就是针对这些场景的一个解决方案。

## 与 Redis 对比

- Pika 的单线程的性能肯定不如 Redis，Pika 是多线程的结构，因此在线程数比较多的情况下，某些数据结构的性能可以优于 Redis ；
- Pika 肯定不是完全优于 Redis 的方案，只是在某些场景下面更适合。所以目前公司内部 Redis，Pika 是共同存在的方案。DBA 会根据业务的场景挑选合适的方案；
- Pika 相对于 Redis，最大的不同就是 Pika 是持久化存储，数据存在磁盘上，而 Redis 是内存存储，由此不同也给 Pika 带来了相对于 Redis 的优势和劣势；


## 大容量 Redis 遇到的问题

### 恢复时间长

- 线上 Redis 一般同时开启 rdb 和 aof ；
- 线上的情况 50G Redis 恢复时间需要差不多 70 分钟；

### 一主多从，主从切换代价大

Redis 在主库挂掉以后，从库升级为新的主库。那么切换主库以后，所有的从库都需要跟新主做一次全同步，全量同步一次大容量的 Redis 代价非常大；

### 缓冲区写满问题

- 为了防止同步缓冲区被复写，dba 给 Redis 设置了 2G 的巨大同步缓冲区，这对于内存资源来讲代价很大；
- 当由于机房之间网络有故障，主从同步出现延迟了大于 2G 以后，就会触发全同步的过程；
- 如果多个从库同时触发全同步的过程， 那么很容易就将主库给拖死。

### 内存太贵

- 线上使用的 Redis 机器是 64G、96G，但只会使用 80% 的空间；
- 如果一个 Redis 的实例是 50G，那么基本一台机器只能运行一个 Redis 实例，特别浪费资源；


## pika 对上述问题的解决（可以作为改进参考）

### 恢复时间长
Pika 的存储引擎使用的是 RocksDB，而 Rocksdb 启动不需要加载全部数据的，只需要加载几 M 的 log 文件就可以启动，因此恢复时间非常快；

### 一主多从，主从切换代价大
在主从切换的时候，新主确定以后，从库会用当前的偏移量尝试与新主做一次部分同步，如果部分同步不成功才做全同步，这样尽可能的减少全同步次数（似乎没有解决问题）；

### 缓冲区写满问题
Pika 不是基于内存缓冲区（维护同步位置信息）进行数据同步的，Pika 主从同步操作记录是保存在本地 binlog 上的，binlog 会随着操作的增长进行 rotate 操作，因此不存在缓冲区写满问题；

### 内存昂贵问题
Pika 的存储引擎使用的是 RocksDB，RocksDB 会同时使用内存和磁盘，减少了对内存的依赖。同时我们尽可能使用 SSD 盘来存放数据，尽可能跟上 Redis 的性能；

## FAQ + Q&A

详细内容看原文吧！


原文：《[360开源的类Redis存储系统:Pika](http://mp.weixin.qq.com/s?__biz=MzAwMDU1MTE1OQ==&mid=2653547160&idx=1&sn=befd195e2aa788775aaf1cc3b6f6fab3&scene=1&srcid=0819GFbZ6omsqTvfVZ0pKba2#rd)》

----------


# 同程旅游缓存系统设计:如何打造Redis时代的完美体系


（下面给出一些独特的点）

## 监控

为了高可用，需要全面的监控。当时我们做了哪些监控呢？

- connected_clients : 已连接客户端的数量
- client_longest_output_list : 当前连接的客户端当中，最长的输出列表
- client_longest_input_buf : 当前连接的客户端当中，最大输入缓存
- blocked_clients : 正在等待阻塞命令（BLPOP、BRPOP、BRPOPLPUSH）的客户端的数量
- used_memory_human : 以人可读的格式返回 Redis 分配的内存总量
- used_memory_rss : 从操作系统的角度，返回 Redis 已分配的内存总量（俗称常驻集大小）。这个值和 top 、 ps 等命令的输出一致。
- replication : 主/从复制信息
- instantaneous_ops_per_sec : 服务器每秒钟执行的命令数量。

## 运维 v.s. 开发

下面是一个接近真实场景运维与开发的对话场景。

```
开发：Redis 为啥不能访问了？
运维：刚刚服务器内存坏了，服务器自动重启了
开发：为什么 Redis 延迟这么大？
运维：不要在 Zset 里放几万条数据，插入排序会死人啊
开发：写进去的 key 为什么不见了？
运维：Redis 超过最大大小了啊，不常用 key 都丢了啊
开发：刚刚为啥读取全失败了
运维：网络临时中断了一下，从机全同步了，在全同步完成之前，从机的读取全部失败
开发：我需要 800G 的 Redis，什么时候能准备好？
运维：线上的服务器最大就 256G，不支持这么大
开发：Redis 慢得像驴，服务器有问题了？
运维：千万级的 KEY，用 keys*，慢是一定了。
```

## 对未来的预期

发展到一定阶段后，到底需要一个什么样的缓存？

- 服务规模：支持大量的缓存访问，应用对缓存大少需求就像贪吃蛇一般
- 集群可管理性：一堆孤岛般的单机服务器缓存服务运维是个迷宫
- 冷热区分：现在缓存中的数据许多并不是永远的热数据
- 访问的规范及可控：还有许多的开发人员对缓存技术了解有限，胡乱用的情况很多
- 在线扩缩容：起初估算的不足到用时发现瓶颈了

原文：《[同程旅游缓存系统设计:如何打造Redis时代的完美体系](http://mp.weixin.qq.com/s?__biz=MzAwMDU1MTE1OQ==&mid=2653547622&idx=1&sn=199cd6d8e3dff7c839935a7613d43e76&scene=1&srcid=0819pe8Fl9YC4aHnaQTowGml#rd)》


----------

# 近千节点的Redis Cluster高可用集群案例:优酷蓝鲸优化实战


## 设计目标

所有的数据都有过期时间，更准确的说是一个全内存的临时存储系统；

- 高效读写；
- 较强的时效性；

## 集群规模

700+ 节点（Redis 作者建议的最大集群规模为 1000 节点）；

## 面临的问题

随着集群规模的扩大

- 带宽压力不断突出；
- 响应时间 RT 方面也会略微升高；

> ⚠️ 与**基于一致性哈希**构建的 Redis 集群不一样，**基于 Redis Cluster** 不能做成超大规模的集群，后者比较适合作为中等规模集群的解决方案；


## 衡量集群稳定性的重要指标

- 吞吐量；
- RT ；

## Redis Cluster 工作原理

Redis 采用单进程模型，除去 bgsave 与 aof rewrite 会 fork 新进程处理外，所有的请求与操作都在主进程内完成。其中比较重量级的请求与操作类型有：

- 客户端请求；
- 集群通讯；
- 从节同步；
- AOF 文件；
- 其它定时任务；

Redis 主线程的主要处理流程（即主要负载点）：

![Redis main process playload overview](http:// "Redis main process playload overview")


由此可知，想要增加 Redis 吞吐量，只需要尽量降低其它任务的负载量就行了，所以提高 Redis 集群吞吐量的方式主要有：

### 适当调大 cluster-node-timeout 参数

我们发现，当集群规模达到一定程度时，集群间消息通讯开销的带宽是极其可观的。

#### 集群通信机制

- 无中心方式实现；
- 通过 Gossip 协议交换消息；

> 基本思想是：为了维护集群状态的统一，节点间互相交换信息，最终所有节点达到一致；


集群通信机制的要点：

- 集群中每个节点都参与；
- 定时发送，默认每隔一秒；
- 交互消息构成：长度为 16,384 的 Bitmap + 集群中 1/10 节点状态（除自身以外）

由代码可知，每个节点状态（clusterMsgDataGossip 结构）大小为 104 byte，所以对于 700 个节点的集群，这部分消息的大小为 70 * 104 = 7280，大约为 7KB；另外，每个 Gossip 消息还需要携带一个长度为 16,384 的 Bitmap，大小为 2KB，所以每个 Gossip 消息大小大约为 9KB。

随着集群规模的不断扩大，每台主机的流量将不断增长，甚至（怀疑）集群间通信流量已经大于前端（外部）请求产生的流量；

实验环境：

- 节点 704 个，分布在 40 台物理主机上，每台物理主机上大约存在 16 个节点；
- 集群采用一主一从模式；
- 集群节点上设置 cluster-node-timeout 为 30 秒；


实验思路：
-  采样时间为 1 分钟；
- 随机选取一个集群节点；
- 截取进入方向和出去方向的流量，并统计出消息条数；

最终计算出目标主机（即一台物理机）因为集群间通讯而产生的带宽开销；


集群通信端口进入方向流量
```shell
tcpflow -cp dst host xx.xx.xx.xx and dst port xxxxx > in.log  // terminate tcpflow after 1 minute
du in.log                             // node receives xxx KBytes data in 1 minute
cat in.log | grep ": Rcmb" | wc -l    // there are xxx messages
```

集群通信端口出去方向流量
```shell
tcpflow -cp src host xx.xx.xx.xx and src port xxxxx > out.log  // terminate tcpflow after 1 minute
du out.log                             // node sends xxx KBytes data in 1 minute
cat out.log | grep ": Rcmb" | wc -l    // there are xxx messages
```

通过实验，可以看到进入方向与出去方向，在 60s 内，都收到大约 2,700 多个数据包；因为 Redis 规定每个节点每一秒只向一个节点发送数据包，所以正常情况每个节点平均 60s 会收到 60 个数据包，为什么会有这么大的差距？

原因是 Redis 选取发送对象节点是随机的，所以会存在两个节点很久都没有交换消息的情况；为了保证集群状态能在较短时间内达到一致性，Redis 规定：当两个节点超过 cluster-node-timeout 的一半时间没有交换消息时，下次心跳交换消息；

接下来看**带宽情况**。先看 Redis Cluster 集群通信端口进入方向每台主机的每秒带宽为

```shell
cluster_ports_in = receive_KBytes * 1024 * 8 * 16 / 60 = xxx bit/s
```
> ⚠️ 上面的 16 是因为一台物理机上存在 16 个节点；

再看 Redis Cluster 集群通信端口出去方向每台主机的每秒带宽为：
```shell
cluster_ports_out = send_KBytes * 1024 * 8 * 16 / 60 = xxx bit/s
```

每台主机进入方向的带宽为
```shell
in = cluster_ports_in + cluster_ports_out
```

每台主机出去方向的带宽为
```shell
out = cluster_ports_in + cluster_ports_out
```

> ⚠️ **为什么是上述两者的求和？**（以节点 A 主动与节点 B 发生消息交换为例进行说明）
>> 首先，A 通过一个随机端口向节点 B 的集群通讯端 17380 发送 PING 消息，之后节点 B 通过 17380 端口向节点 A 发送 PONG 消息，PONG 消息的内容与 PING 消息的内容相似，每个消息的大小也一样（9KB）；
>>
>> 同理，当节点 B 主动与节点 A 发生消息交换时也是同样的过程；
>>
>> 可以看出，节点 A 进入方向的带宽，不仅包含来自集群通讯端口 17380 的部分，还包含来自随机端口的部分；而对于节点 A 进入方向来自随机端口的带宽，正是其它节点出去方向的带宽；所以每台主机进入方向的带宽即可通过上边的求和公式得到；同理，出去方向的带宽与进入方带宽计算公式相同；


#### cluster-node-timeout 对带宽的影响

- 设置 cluster-node-timeout 为 20 秒；
- 获取每台物理机进出口总带宽；
- 总带宽 - 集群通信带宽 = 前端（外部）请求带宽

调整 cluster-node-timeout 为 30 秒重新计算；可以看到带宽下降效果非常明显；

两个实验结论：
- 集群间通信占用大量带宽资源；
- 调整 cluster-node-timeout 参数能有效降低带宽；


#### Redis Cluster 判定节点为 fail 的机制

⚠️ 并不是 cluster-node-timeout 越大越好，**当 cluster-node-timeout 增大的时候，集群判断节点 fail 的时间会增加，从而 failover 的时间窗口会增加**；

集群判定某个节点为 fail ，所需时间的计算公式如下：
```shell
node-fail-judge-time = cluster-node-timeout + cluster-node-timeout / 2 + 10
```

1. 当节点向失败节点发出 `PING` 消息，并且在 `cluster-node-timeout` 时间内没有收到失败节点的 PONG 消息，此时判定它为 `pfail` ；

> pfail 即部分失败，它是一种中间状态，该状态随着集群心跳不断传播；

2. 再经过 `1/2` 的 `cluster-node-timeout` 时间后，（集群中的）所有节点都会（已经）与失败节点发生（完成）心跳探测，并将其标记为 pfail ；（⚠️ 当然也可能不需要这么长时间，因为其它节点之间的心跳同样会传递 pfail 状态，这里姑且以最大时间计算）

3. Redis Cluster 规定：当集群中超过一半以上节点认为一个节点为 pfail 状态时，会把它标记为 fail 状态，并广播给其他所有节点；

> 对于每个节点而言，平均一秒钟会收到一个心跳包，每次心跳都会携带数量为集群节点总数十分之一的、随机选取的节点信息。因此问题可以抽象为：
>> 经过多长时间，一个节点会（在集群中）积累到一半的 pfail 状态数；
> 很显然，这是一个概率问题，简单起见，公式里直接取了一个能在较大概率上保证 fail 判定成立的时间值，10 秒；

所以上述公式不是达到这么长时间一定会判定节点为 fail，而是经过这么长时间集群有很大概率会判定节点 fail 。

Redis Cluster 默认 cluster-node-timeout 为 15s，我们将它设置成了 30s。也就是说 700 节点的集群，集群间带宽开销为 104.5MBit / s，判定节点失败时间窗口大概为 55s，实际上大多数情况都小于 55s，因为上边的计算都是按照高位时间估算的。

总而言之，对于大的 Redis 集群 cluster-node-timeout 参数的需要谨慎设定。











### 控制主节点写命令传播






 




本文用于汇总 Redis 内存相关问题！

1. 为什么Redis内存不宜过大
2. 节约内存：Instagram的Redis实践
3. 360开源的类Redis存储系统:Pika
4. 同程旅游缓存系统设计:如何打造Redis时代的完美体系

----------

# 为什么Redis内存不宜过大

## 主库宕机

主库宕机容灾过程：在主库宕机的时候，最常见的容灾策略为“切主”。具体为从该集群剩余从库中选出一个从库并将其升级为主库，之后再将剩余从库挂载至其下成为其从库，最终恢复整个主从集群结构。

> ⚠️ 以上是一个完整的容灾过程，而代价最大的过程为**从库的重新挂载**，而非主库的切换。

这是因为 redis 无法像 mysql 、mongodb 那样基于同步的点位在主库发生变化后从新的主库继续同步数据。 在redis 集群中一旦从库换主，redis 的做法是将更换主库的从库清空，然后从新主库完整同步一份数据再进行续传。

整个从库重做流程是这样的：
- 主库 bgsave 自身数据到磁盘；
- 主库发送 rdb 文件到从库；
- 从库开始加载；
- 加载完毕后开始续传，同时开始提供服务；

很明显，在这个过程中 redis 的内存体积越大，则以上每一个步骤的时间都会被拉长，实际测试数据如下（在足够好的机器上）

内存体积 | 从库重做时间
--------|--------------
5G  | 4min
10G | 8min
20G | 18min
30G | 30min
50G | 60min

可以看到，当数据达到（占用内存）20G 的时候，一个从库的恢复时间已经被拉长到了将近 20 分钟，如果有 10个从库，那么如果依次恢复则共需 200 分钟，如果此时该从库承担着大量的读取请求，你能够忍受这么长的恢复时间吗？

看到这里你肯定会问：**为什么不能同时重做所有从库？**这是因为如果所有从库同时向主库请求 rdb 文件，那么主库的网卡则立即跑满，从而进入一个无法正常提供服务的状态，此时主库（可能会）又死了，将雪上加霜。

当然，我们可以批量恢复从库，例如两两一组（确保网卡不被跑满），那么全部从库的恢复时间也仅仅从 200 分钟降低到了 100 分钟，但这仍然是五十步笑百步；

另一个重要问题和上面的第四点有关，续传（的实现）可以理解为（基于）一个简化的 mongodb 的 oplog ，它是一个体积固定的内存空间，我们称之为“同步缓冲区”。

> 需要补充理论知识；

redis 主库的写入操作都会在该缓冲区中存放一份然后发送给从库，而如果在上文中 1, 2, 3 步耗时太久那么很可能这个同步缓冲区被重写，此时从库将无法找到对应的续传位置；因为，从库只能重做 1, 2, 3 步骤；

因为我们无法解决 1，2，3 步骤的耗时，因此该从库将进入无限次数的恶性循环：不停的向主库请求完整数据，结果对主库的网卡造成严重影响。

## 扩容问题

很多时候会出现流量的突发性增长，通常在找到原因之前，我们的应急做法就是**扩容**了。

而根据上面的表格，一个 20G 的 redis 扩容一个从库需要将近 20 分钟，而问题是业务能够容忍 20 分钟的业务停摆么？可能还没扩好业务就死翘翘了。

## 网络问题导致从库重做进而引发雪崩

该场景下的最大问题是：**主库与从库发生同步中断，与此同时主库仍然在接受写入请求**；一旦中断时间过长，同步缓冲区就很可能被复写（发生覆盖），进而导致从库的上一次同步位置丢失；在网络恢复后，虽然（此时）主库没有（继续）发生变化，但由于从库的同步位置已丢失，从库只能通过重做的方式确保与主库的一致，也就是之前提到的 1，2，3，4 步骤；如果此时主库内存体积过大，那么从库重做的速度就会很慢，而发送到从库的读请求就会受到严重影响；同时由于传输的 rdb 文件的体积过大，主库的网卡在相当长的一段时间内都会受到严重影响；

## 内存越大，触发持久化的操作阻塞主线程的时间越长

Redis 是单线程内存数据库，在 redis 需要执行耗时操作时，会 fork 一个新进程来做，比如 bgsave 或bgrewriteaof 。 虽然 fork 新进程时可共享的数据内容不需要复制，但会复制父进程空间中的内存页表，这个复制是由主线程来做的，会阻塞所有的读写操作，并且随着内存使用量越大耗时越长。例如：内存 20G 的 redis ，bgsave 复制内存页表耗时约为 750ms ，redis 主线程也会因为它阻塞 750ms ；


## 解决办法

解决办法就是极力减少内存的使用，一般情况下，做法如下：

### 设置过期时间
对具有时效性的 key 设置过期时间，通过 redis 自身的过期 key 清理策略来降低过期 key 对于内存的占用，同时也能够减少业务的麻烦，不需要定期清理了；

### 不存放垃圾到 redis 中
这虽然是废话，但也意味着很多人会犯这种错误；

###及时清理无用数据
例如一个 redis 承载了 3 个业务的数据，一段时间后有 2 个业务下线了，此时就应该把这两个业务的相关数据立刻清理掉；

### 尽量对数据进行压缩
例如一些长文本形式的数据，压缩能够大幅度降低内存占用；

### 关注内存增长并定位大容量 key
不管是 DBA 还是开发人员，只要用 redis 就必须关注内存；否则，你其实就是不称职的；常用方式是：分析 redis 实例中哪些 key 比较大，从而帮助业务快速定位异常 key（非预期增长的 key ，往往是问题之源）；

### pika
如果实在不想搞的那么累，那就把业务迁移到 360 新开源的 pika 上面，这样就不用太关注内存了，redis 内存太大引发的问题，那也都不是问题了（存在安利嫌疑）；

> ⚠️ Pika 主要解决的问题是：用户使用 Redis 的内存大小超过 50G、80G 等等这样的情况，此时会遇到
>> - 启动恢复时间长；
>> - 主多从代价大；
>> - 硬件成本贵；
>> - 缓冲区容易写满
> 
> 等问题，Pika 就是针对这些场景的一个解决方案，不能单纯的认为其优于 Redis 方案；


原文：《[为什么Redis内存不宜过大](https://mp.weixin.qq.com/s?__biz=MzA4NDExOTEyOA==&mid=2649779368&idx=4&sn=a8b5f0b6c399ed40938d30a7e6a6c63b&scene=1&srcid=0817sL4YElry4EEuyBFb2pCV&pass_ticket=3Q%2Fz25YbaVx9NmwDaGh%2F4swJn1%2BWROo8G7iEhwUp1JmGJDYvv79bpY0TWQqYJKQq#rd)》


----------

# 节约内存：Instagram的Redis实践

条件：基于 Redis 的 String 结构来做 key-value 存储；

关键点：
- 数据量预估＋Redis 内存容量计算；
- Redis 中的 key 不会进行字符串到数字的转换（即使其为纯数字）； 

条件：基于 Redis 的 Hash 结构来做 key-value 存储；

关键点：
- 通过 hash-zipmap-max-entries 参数控制压缩判定阈值；

> 开发者实验：将 hash-zipmap-max-entries 设置为 1000 时性能比较好，超过 1000 后 HSET 命令就会导致 CPU消耗变得非常大；



原文：《[节约内存：Instagram的Redis实践](http://mp.weixin.qq.com/s?__biz=MzA5Njg1OTI5Mg==&mid=2651025383&idx=1&sn=4a3786b6b93fa90b2f6409ebb6b3504f&scene=1&srcid=0819DOyloixa4YRZxuA0NKsb#rd)》

----------


# 360开源的类Redis存储系统:Pika


## 使用场景

Pika 主要解决的是用户使用 Redis 的内存大小超过 50G、80G 等等这样的情况，会遇到启动恢复时间长，一主多从代价大，硬件成本贵，缓冲区容易写满等问题。Pika 就是针对这些场景的一个解决方案。

## 与 Redis 对比

- Pika 的单线程的性能肯定不如 Redis，Pika 是多线程的结构，因此在线程数比较多的情况下，某些数据结构的性能可以优于 Redis ；
- Pika 肯定不是完全优于 Redis 的方案，只是在某些场景下面更适合。所以目前公司内部 Redis，Pika 是共同存在的方案。DBA 会根据业务的场景挑选合适的方案；
- Pika 相对于 Redis，最大的不同就是 Pika 是持久化存储，数据存在磁盘上，而 Redis 是内存存储，由此不同也给 Pika 带来了相对于 Redis 的优势和劣势；


## 大容量 Redis 遇到的问题

### 恢复时间长

- 线上 Redis 一般同时开启 rdb 和 aof ；
- 线上的情况 50G Redis 恢复时间需要差不多 70 分钟；

### 一主多从，主从切换代价大

Redis 在主库挂掉以后，从库升级为新的主库。那么切换主库以后，所有的从库都需要跟新主做一次全同步，全量同步一次大容量的 Redis 代价非常大；

### 缓冲区写满问题

- 为了防止同步缓冲区被复写，dba 给 Redis 设置了 2G 的巨大同步缓冲区，这对于内存资源来讲代价很大；
- 当由于机房之间网络有故障，主从同步出现延迟了大于 2G 以后，就会触发全同步的过程；
- 如果多个从库同时触发全同步的过程， 那么很容易就将主库给拖死。

### 内存太贵

- 线上使用的 Redis 机器是 64G、96G，但只会使用 80% 的空间；
- 如果一个 Redis 的实例是 50G，那么基本一台机器只能运行一个 Redis 实例，特别浪费资源；


## pika 对上述问题的解决（可以作为改进参考）

### 恢复时间长
Pika 的存储引擎使用的是 RocksDB，而 Rocksdb 启动不需要加载全部数据的，只需要加载几 M 的 log 文件就可以启动，因此恢复时间非常快；

### 一主多从，主从切换代价大
在主从切换的时候，新主确定以后，从库会用当前的偏移量尝试与新主做一次部分同步，如果部分同步不成功才做全同步，这样尽可能的减少全同步次数（似乎没有解决问题）；

### 缓冲区写满问题
Pika 不是基于内存缓冲区（维护同步位置信息）进行数据同步的，Pika 主从同步操作记录是保存在本地 binlog 上的，binlog 会随着操作的增长进行 rotate 操作，因此不存在缓冲区写满问题；

### 内存昂贵问题
Pika 的存储引擎使用的是 RocksDB，RocksDB 会同时使用内存和磁盘，减少了对内存的依赖。同时我们尽可能使用 SSD 盘来存放数据，尽可能跟上 Redis 的性能；

## FAQ + Q&A

详细内容看原文吧！


原文：《[360开源的类Redis存储系统:Pika](http://mp.weixin.qq.com/s?__biz=MzAwMDU1MTE1OQ==&mid=2653547160&idx=1&sn=befd195e2aa788775aaf1cc3b6f6fab3&scene=1&srcid=0819GFbZ6omsqTvfVZ0pKba2#rd)》

----------


# 同程旅游缓存系统设计:如何打造Redis时代的完美体系


（下面给出一些独特的点）

## 监控

为了高可用，需要全面的监控。当时我们做了哪些监控呢？

- connected_clients : 已连接客户端的数量
- client_longest_output_list : 当前连接的客户端当中，最长的输出列表
- client_longest_input_buf : 当前连接的客户端当中，最大输入缓存
- blocked_clients : 正在等待阻塞命令（BLPOP、BRPOP、BRPOPLPUSH）的客户端的数量
- used_memory_human : 以人可读的格式返回 Redis 分配的内存总量
- used_memory_rss : 从操作系统的角度，返回 Redis 已分配的内存总量（俗称常驻集大小）。这个值和 top 、 ps 等命令的输出一致。
- replication : 主/从复制信息
- instantaneous_ops_per_sec : 服务器每秒钟执行的命令数量。

## 运维 v.s. 开发

下面是一个接近真实场景运维与开发的对话场景。

```
开发：Redis 为啥不能访问了？
运维：刚刚服务器内存坏了，服务器自动重启了
开发：为什么 Redis 延迟这么大？
运维：不要在 Zset 里放几万条数据，插入排序会死人啊
开发：写进去的 key 为什么不见了？
运维：Redis 超过最大大小了啊，不常用 key 都丢了啊
开发：刚刚为啥读取全失败了
运维：网络临时中断了一下，从机全同步了，在全同步完成之前，从机的读取全部失败
开发：我需要 800G 的 Redis，什么时候能准备好？
运维：线上的服务器最大就 256G，不支持这么大
开发：Redis 慢得像驴，服务器有问题了？
运维：千万级的 KEY，用 keys*，慢是一定了。
```

## 对未来的预期

发展到一定阶段后，到底需要一个什么样的缓存？

- 服务规模：支持大量的缓存访问，应用对缓存大少需求就像贪吃蛇一般
- 集群可管理性：一堆孤岛般的单机服务器缓存服务运维是个迷宫
- 冷热区分：现在缓存中的数据许多并不是永远的热数据
- 访问的规范及可控：还有许多的开发人员对缓存技术了解有限，胡乱用的情况很多
- 在线扩缩容：起初估算的不足到用时发现瓶颈了

原文：《[同程旅游缓存系统设计:如何打造Redis时代的完美体系](http://mp.weixin.qq.com/s?__biz=MzAwMDU1MTE1OQ==&mid=2653547622&idx=1&sn=199cd6d8e3dff7c839935a7613d43e76&scene=1&srcid=0819pe8Fl9YC4aHnaQTowGml#rd)》


----------



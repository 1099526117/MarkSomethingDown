
[toc]

----------


本文用于汇总 Redis 内存相关问题！

1. 为什么Redis内存不宜过大
2. 节约内存：Instagram的Redis实践
3. 360开源的类Redis存储系统:Pika
4. 同程旅游缓存系统设计:如何打造Redis时代的完美体系
5. 近千节点的Redis Cluster高可用集群案例:优酷蓝鲸优化实战
6. 用最少的机器支撑万亿级访问，微博6年Redis优化历程
7. Codis作者黄东旭细说分布式Redis架构设计和踩过的那些坑们

----------

# 为什么Redis内存不宜过大

## 主库宕机

主库宕机容灾过程：在主库宕机的时候，最常见的容灾策略为“切主”。具体为从该集群剩余从库中选出一个从库并将其升级为主库，之后再将剩余从库挂载至其下成为其从库，最终恢复整个主从集群结构。

> ⚠️ 以上是一个完整的容灾过程，而代价最大的过程为**从库的重新挂载**，而非主库的切换。

这是因为 redis 无法像 mysql 、mongodb 那样基于同步的点位在主库发生变化后从新的主库继续同步数据。 在redis 集群中一旦从库换主，redis 的做法是将更换主库的从库清空，然后从新主库完整同步一份数据再进行续传。

整个从库重做流程是这样的：
- 主库 bgsave 自身数据到磁盘；
- 主库发送 rdb 文件到从库；
- 从库开始加载；
- 加载完毕后开始续传，同时开始提供服务；

很明显，在这个过程中 redis 的内存体积越大，则以上每一个步骤的时间都会被拉长，实际测试数据如下（在足够好的机器上）

内存体积 | 从库重做时间
--------|--------------
5G  | 4min
10G | 8min
20G | 18min
30G | 30min
50G | 60min

可以看到，当数据达到（占用内存）20G 的时候，一个从库的恢复时间已经被拉长到了将近 20 分钟，如果有 10个从库，那么如果依次恢复则共需 200 分钟，如果此时该从库承担着大量的读取请求，你能够忍受这么长的恢复时间吗？

看到这里你肯定会问：**为什么不能同时重做所有从库？**这是因为如果所有从库同时向主库请求 rdb 文件，那么主库的网卡则立即跑满，从而进入一个无法正常提供服务的状态，此时主库（可能会）又死了，将雪上加霜。

当然，我们可以批量恢复从库，例如两两一组（确保网卡不被跑满），那么全部从库的恢复时间也仅仅从 200 分钟降低到了 100 分钟，但这仍然是五十步笑百步；

另一个重要问题和上面的第四点有关，续传（的实现）可以理解为（基于）一个简化的 mongodb 的 oplog ，它是一个体积固定的内存空间，我们称之为“同步缓冲区”。

> 需要补充理论知识；

redis 主库的写入操作都会在该缓冲区中存放一份然后发送给从库，而如果在上文中 1, 2, 3 步耗时太久那么很可能这个同步缓冲区被重写，此时从库将无法找到对应的续传位置；因为，从库只能重做 1, 2, 3 步骤；

因为我们无法解决 1，2，3 步骤的耗时，因此该从库将进入无限次数的恶性循环：不停的向主库请求完整数据，结果对主库的网卡造成严重影响。

## 扩容问题

很多时候会出现流量的突发性增长，通常在找到原因之前，我们的应急做法就是**扩容**了。

而根据上面的表格，一个 20G 的 redis 扩容一个从库需要将近 20 分钟，而问题是业务能够容忍 20 分钟的业务停摆么？可能还没扩好业务就死翘翘了。

## 网络问题导致从库重做进而引发雪崩

该场景下的最大问题是：**主库与从库发生同步中断，与此同时主库仍然在接受写入请求**；一旦中断时间过长，同步缓冲区就很可能被复写（发生覆盖），进而导致从库的上一次同步位置丢失；在网络恢复后，虽然（此时）主库没有（继续）发生变化，但由于从库的同步位置已丢失，从库只能通过重做的方式确保与主库的一致，也就是之前提到的 1，2，3，4 步骤；如果此时主库内存体积过大，那么从库重做的速度就会很慢，而发送到从库的读请求就会受到严重影响；同时由于传输的 rdb 文件的体积过大，主库的网卡在相当长的一段时间内都会受到严重影响；

## 内存越大，触发持久化的操作阻塞主线程的时间越长

Redis 是单线程内存数据库，在 redis 需要执行耗时操作时，会 fork 一个新进程来做，比如 bgsave 或bgrewriteaof 。 虽然 fork 新进程时可共享的数据内容不需要复制，但会复制父进程空间中的内存页表，这个复制是由主线程来做的，会阻塞所有的读写操作，并且随着内存使用量越大耗时越长。例如：内存 20G 的 redis ，bgsave 复制内存页表耗时约为 750ms ，redis 主线程也会因为它阻塞 750ms ；


## 解决办法

解决办法就是极力减少内存的使用，一般情况下，做法如下：

### 设置过期时间
对具有时效性的 key 设置过期时间，通过 redis 自身的过期 key 清理策略来降低过期 key 对于内存的占用，同时也能够减少业务的麻烦，不需要定期清理了；

### 不存放垃圾到 redis 中
这虽然是废话，但也意味着很多人会犯这种错误；

###及时清理无用数据
例如一个 redis 承载了 3 个业务的数据，一段时间后有 2 个业务下线了，此时就应该把这两个业务的相关数据立刻清理掉；

### 尽量对数据进行压缩
例如一些长文本形式的数据，压缩能够大幅度降低内存占用；

### 关注内存增长并定位大容量 key
不管是 DBA 还是开发人员，只要用 redis 就必须关注内存；否则，你其实就是不称职的；常用方式是：分析 redis 实例中哪些 key 比较大，从而帮助业务快速定位异常 key（非预期增长的 key ，往往是问题之源）；

### pika
如果实在不想搞的那么累，那就把业务迁移到 360 新开源的 pika 上面，这样就不用太关注内存了，redis 内存太大引发的问题，那也都不是问题了（存在安利嫌疑）；

> ⚠️ Pika 主要解决的问题是：用户使用 Redis 的内存大小超过 50G、80G 等等这样的情况，此时会遇到
>> - 启动恢复时间长；
>> - 主多从代价大；
>> - 硬件成本贵；
>> - 缓冲区容易写满
> 
> 等问题，Pika 就是针对这些场景的一个解决方案，不能单纯的认为其优于 Redis 方案；


原文：《[为什么Redis内存不宜过大](https://mp.weixin.qq.com/s?__biz=MzA4NDExOTEyOA==&mid=2649779368&idx=4&sn=a8b5f0b6c399ed40938d30a7e6a6c63b&scene=1&srcid=0817sL4YElry4EEuyBFb2pCV&pass_ticket=3Q%2Fz25YbaVx9NmwDaGh%2F4swJn1%2BWROo8G7iEhwUp1JmGJDYvv79bpY0TWQqYJKQq#rd)》


----------

# 节约内存：Instagram的Redis实践

条件：基于 Redis 的 String 结构来做 key-value 存储；

关键点：
- 数据量预估＋Redis 内存容量计算；
- Redis 中的 key 不会进行字符串到数字的转换（即使其为纯数字）； 

条件：基于 Redis 的 Hash 结构来做 key-value 存储；

关键点：
- 通过 hash-zipmap-max-entries 参数控制压缩判定阈值；

> 开发者实验：将 hash-zipmap-max-entries 设置为 1000 时性能比较好，超过 1000 后 HSET 命令就会导致 CPU消耗变得非常大；



原文：《[节约内存：Instagram的Redis实践](http://mp.weixin.qq.com/s?__biz=MzA5Njg1OTI5Mg==&mid=2651025383&idx=1&sn=4a3786b6b93fa90b2f6409ebb6b3504f&scene=1&srcid=0819DOyloixa4YRZxuA0NKsb#rd)》

----------


# 360开源的类Redis存储系统:Pika


## 使用场景

Pika 主要解决的是用户使用 Redis 的内存大小超过 50G、80G 等等这样的情况，会遇到启动恢复时间长，一主多从代价大，硬件成本贵，缓冲区容易写满等问题。Pika 就是针对这些场景的一个解决方案。

## 与 Redis 对比

- Pika 的单线程的性能肯定不如 Redis，Pika 是多线程的结构，因此在线程数比较多的情况下，某些数据结构的性能可以优于 Redis ；
- Pika 肯定不是完全优于 Redis 的方案，只是在某些场景下面更适合。所以目前公司内部 Redis，Pika 是共同存在的方案。DBA 会根据业务的场景挑选合适的方案；
- Pika 相对于 Redis，最大的不同就是 Pika 是持久化存储，数据存在磁盘上，而 Redis 是内存存储，由此不同也给 Pika 带来了相对于 Redis 的优势和劣势；


## 大容量 Redis 遇到的问题

### 恢复时间长

- 线上 Redis 一般同时开启 rdb 和 aof ；
- 线上的情况 50G Redis 恢复时间需要差不多 70 分钟；

### 一主多从，主从切换代价大

Redis 在主库挂掉以后，从库升级为新的主库。那么切换主库以后，所有的从库都需要跟新主做一次全同步，全量同步一次大容量的 Redis 代价非常大；

### 缓冲区写满问题

- 为了防止同步缓冲区被复写，dba 给 Redis 设置了 2G 的巨大同步缓冲区，这对于内存资源来讲代价很大；
- 当由于机房之间网络有故障，主从同步出现延迟了大于 2G 以后，就会触发全同步的过程；
- 如果多个从库同时触发全同步的过程， 那么很容易就将主库给拖死。

### 内存太贵

- 线上使用的 Redis 机器是 64G、96G，但只会使用 80% 的空间；
- 如果一个 Redis 的实例是 50G，那么基本一台机器只能运行一个 Redis 实例，特别浪费资源；


## pika 对上述问题的解决（可以作为改进参考）

### 恢复时间长
Pika 的存储引擎使用的是 RocksDB，而 Rocksdb 启动不需要加载全部数据的，只需要加载几 M 的 log 文件就可以启动，因此恢复时间非常快；

### 一主多从，主从切换代价大
在主从切换的时候，新主确定以后，从库会用当前的偏移量尝试与新主做一次部分同步，如果部分同步不成功才做全同步，这样尽可能的减少全同步次数（似乎没有解决问题）；

### 缓冲区写满问题
Pika 不是基于内存缓冲区（维护同步位置信息）进行数据同步的，Pika 主从同步操作记录是保存在本地 binlog 上的，binlog 会随着操作的增长进行 rotate 操作，因此不存在缓冲区写满问题；

### 内存昂贵问题
Pika 的存储引擎使用的是 RocksDB，RocksDB 会同时使用内存和磁盘，减少了对内存的依赖。同时我们尽可能使用 SSD 盘来存放数据，尽可能跟上 Redis 的性能；

## FAQ + Q&A

详细内容看原文吧！


原文：《[360开源的类Redis存储系统:Pika](http://mp.weixin.qq.com/s?__biz=MzAwMDU1MTE1OQ==&mid=2653547160&idx=1&sn=befd195e2aa788775aaf1cc3b6f6fab3&scene=1&srcid=0819GFbZ6omsqTvfVZ0pKba2#rd)》

----------


# 同程旅游缓存系统设计:如何打造Redis时代的完美体系


（下面给出一些独特的点）

## 监控

为了高可用，需要全面的监控。当时我们做了哪些监控呢？

- connected_clients : 已连接客户端的数量
- client_longest_output_list : 当前连接的客户端当中，最长的输出列表
- client_longest_input_buf : 当前连接的客户端当中，最大输入缓存
- blocked_clients : 正在等待阻塞命令（BLPOP、BRPOP、BRPOPLPUSH）的客户端的数量
- used_memory_human : 以人可读的格式返回 Redis 分配的内存总量
- used_memory_rss : 从操作系统的角度，返回 Redis 已分配的内存总量（俗称常驻集大小）。这个值和 top 、 ps 等命令的输出一致。
- replication : 主/从复制信息
- instantaneous_ops_per_sec : 服务器每秒钟执行的命令数量。

## 运维 v.s. 开发

下面是一个接近真实场景运维与开发的对话场景。

```
开发：Redis 为啥不能访问了？
运维：刚刚服务器内存坏了，服务器自动重启了
开发：为什么 Redis 延迟这么大？
运维：不要在 Zset 里放几万条数据，插入排序会死人啊
开发：写进去的 key 为什么不见了？
运维：Redis 超过最大大小了啊，不常用 key 都丢了啊
开发：刚刚为啥读取全失败了
运维：网络临时中断了一下，从机全同步了，在全同步完成之前，从机的读取全部失败
开发：我需要 800G 的 Redis，什么时候能准备好？
运维：线上的服务器最大就 256G，不支持这么大
开发：Redis 慢得像驴，服务器有问题了？
运维：千万级的 KEY，用 keys*，慢是一定了。
```

## 对未来的预期

发展到一定阶段后，到底需要一个什么样的缓存？

- 服务规模：支持大量的缓存访问，应用对缓存大少需求就像贪吃蛇一般
- 集群可管理性：一堆孤岛般的单机服务器缓存服务运维是个迷宫
- 冷热区分：现在缓存中的数据许多并不是永远的热数据
- 访问的规范及可控：还有许多的开发人员对缓存技术了解有限，胡乱用的情况很多
- 在线扩缩容：起初估算的不足到用时发现瓶颈了

原文：《[同程旅游缓存系统设计:如何打造Redis时代的完美体系](http://mp.weixin.qq.com/s?__biz=MzAwMDU1MTE1OQ==&mid=2653547622&idx=1&sn=199cd6d8e3dff7c839935a7613d43e76&scene=1&srcid=0819pe8Fl9YC4aHnaQTowGml#rd)》


----------

# 近千节点的Redis Cluster高可用集群案例:优酷蓝鲸优化实战


## 设计目标

所有的数据都有过期时间，更准确的说是一个全内存的临时存储系统；

- 高效读写；
- 较强的时效性；

## 集群规模

700+ 节点（Redis 作者建议的最大集群规模为 1000 节点）；

## 面临的问题

随着集群规模的扩大

- 带宽压力不断突出；
- 响应时间 RT 方面也会略微升高；

> ⚠️ 与**基于一致性哈希**构建的 Redis 集群不一样，**基于 Redis Cluster** 不能做成超大规模的集群，后者比较适合作为中等规模集群的解决方案；


## 衡量集群稳定性的重要指标

- 吞吐量；
- RT ；

## Redis Cluster 工作原理

Redis 采用单进程模型，除去 bgsave 与 aof rewrite 会 fork 新进程处理外，所有的请求与操作都在主进程内完成。其中比较重量级的请求与操作类型有：

- 客户端请求；
- 集群通讯；
- 从节同步；
- AOF 文件；
- 其它定时任务；

Redis 主线程的主要处理流程（即主要负载点）：

![Redis main process playload overview](https://github.com/moooofly/ImageCache/blob/master/Pictures/Redis%20main%20process%20playload%20overview.png "Redis main process playload overview")


由此可知，想要增加 Redis 吞吐量，只需要尽量降低其它任务的负载量就行了，所以提高 Redis 集群吞吐量的方式主要有：

### 适当调大 cluster-node-timeout 参数

我们发现，当集群规模达到一定程度时，集群间消息通讯开销的带宽是极其可观的。

#### 集群通信机制

- 无中心方式实现；
- 通过 Gossip 协议交换消息；

> 基本思想是：为了维护集群状态的统一，节点间互相交换信息，最终所有节点达到一致；

![Gossip in Redis Cluster](https://github.com/moooofly/ImageCache/blob/master/Pictures/Gossip%20in%20Redis%20Cluster.png "Gossip in Redis Cluster")


集群通信机制的要点：

- 集群中每个节点都参与；
- 定时发送，默认每隔一秒；
- 交互消息构成：长度为 16,384 的 Bitmap + 集群中 1/10 节点状态（除自身以外）

由代码可知，每个节点状态（clusterMsgDataGossip 结构）大小为 104 byte，所以对于 700 个节点的集群，这部分消息的大小为 70 * 104 = 7280，大约为 7KB；另外，每个 Gossip 消息还需要携带一个长度为 16,384 的 Bitmap，大小为 2KB，所以每个 Gossip 消息大小大约为 9KB。

随着集群规模的不断扩大，每台主机的流量将不断增长，甚至（怀疑）集群间通信流量已经大于前端（外部）请求产生的流量；

实验环境：

- 节点 704 个，分布在 40 台物理主机上，每台物理主机上大约存在 16 个节点；
- 集群采用一主一从模式；
- 集群节点上设置 cluster-node-timeout 为 30 秒；


实验思路：
-  采样时间为 1 分钟；
- 随机选取一个集群节点；
- 截取进入方向和出去方向的流量，并统计出消息条数；

最终计算出目标主机（即一台物理机）因为集群间通讯而产生的带宽开销；


集群通信端口进入方向流量
```shell
tcpflow -cp dst host xx.xx.xx.xx and dst port xxxxx > in.log  // terminate tcpflow after 1 minute
du in.log                             // node receives xxx KBytes data in 1 minute
cat in.log | grep ": Rcmb" | wc -l    // there are xxx messages
```

集群通信端口出去方向流量
```shell
tcpflow -cp src host xx.xx.xx.xx and src port xxxxx > out.log  // terminate tcpflow after 1 minute
du out.log                             // node sends xxx KBytes data in 1 minute
cat out.log | grep ": Rcmb" | wc -l    // there are xxx messages
```

通过实验，可以看到进入方向与出去方向，在 60s 内，都收到大约 2,700 多个数据包；因为 Redis 规定每个节点每一秒只向一个节点发送数据包，所以正常情况每个节点平均 60s 会收到 60 个数据包，为什么会有这么大的差距？

原因是 Redis 选取发送对象节点是随机的，所以会存在两个节点很久都没有交换消息的情况；为了保证集群状态能在较短时间内达到一致性，Redis 规定：当两个节点超过 cluster-node-timeout 的一半时间没有交换消息时，下次心跳交换消息；

接下来看**带宽情况**。先看 Redis Cluster 集群通信端口进入方向每台主机的每秒带宽为

```shell
cluster_ports_in = receive_KBytes * 1024 * 8 * 16 / 60 = xxx bit/s
```
> ⚠️ 上面的 16 是因为一台物理机上存在 16 个节点；

再看 Redis Cluster 集群通信端口出去方向每台主机的每秒带宽为：
```shell
cluster_ports_out = send_KBytes * 1024 * 8 * 16 / 60 = xxx bit/s
```

每台主机进入方向的带宽为
```shell
in = cluster_ports_in + cluster_ports_out
```

每台主机出去方向的带宽为
```shell
out = cluster_ports_in + cluster_ports_out
```

![Redis Cluster msg exchange](https://github.com/moooofly/ImageCache/blob/master/Pictures/Redis%20Cluster%20msg%20exchange.png "Redis Cluster msg exchange")

> ⚠️ **为什么是上述两者的求和？**（以节点 A 主动与节点 B 发生消息交换为例进行说明）
>> 首先，A 通过一个随机端口向节点 B 的集群通讯端 17380 发送 PING 消息，之后节点 B 通过 17380 端口向节点 A 发送 PONG 消息，PONG 消息的内容与 PING 消息的内容相似，每个消息的大小也一样（9KB）；
>>
>> 同理，当节点 B 主动与节点 A 发生消息交换时也是同样的过程；
>>
>> 可以看出，节点 A 进入方向的带宽，不仅包含来自集群通讯端口 17380 的部分，还包含来自随机端口的部分；而对于节点 A 进入方向来自随机端口的带宽，正是其它节点出去方向的带宽；所以每台主机进入方向的带宽即可通过上边的求和公式得到；同理，出去方向的带宽与进入方带宽计算公式相同；



#### cluster-node-timeout 对带宽的影响

- 设置 cluster-node-timeout 为 20 秒；
- 获取每台物理机进出口总带宽；
- 总带宽 - 集群通信带宽 = 前端（外部）请求带宽

调整 cluster-node-timeout 为 30 秒重新计算；可以看到带宽下降效果非常明显；

两个实验结论：
- 集群间通信占用大量带宽资源；
- 调整 cluster-node-timeout 参数能有效降低带宽；


#### Redis Cluster 判定节点为 fail 的机制

首先可以确定一点：并不是 `cluster-node-timeout` 越大越好；因为**当 cluster-node-timeout 增大的时候，集群判断节点 fail 的时间会增加，从而 failover 的时间窗口会增加**；

集群判定某个节点为 fail ，所需时间的计算公式如下：
```shell
node-fail-judge-time = cluster-node-timeout + cluster-node-timeout / 2 + 10
```

-  当节点向失败节点发出 `PING` 消息，并且在 `cluster-node-timeout` 时间内没有收到失败节点的 PONG 消息，此时判定它为 `pfail` ；

> pfail 即部分失败，它是一种中间状态，该状态随着集群心跳不断传播；

- 再经过 `1/2` 的 `cluster-node-timeout` 时间后，（集群中的）所有节点都会（已经）与失败节点发生（完成）心跳探测，并将其标记为 pfail ；（⚠️ 当然也可能不需要这么长时间，因为其它节点之间的心跳同样会传递 pfail 状态，这里姑且以最大时间计算）

- Redis Cluster 规定：当集群中超过一半以上节点认为一个节点为 pfail 状态时，会把它标记为 fail 状态，并广播给其他所有节点；

> 对于每个节点而言，平均一秒钟会收到一个心跳包，每次心跳都会携带数量为集群节点总数十分之一的、随机选取的节点信息。因此问题可以抽象为：
>> 经过多长时间，一个节点会（在集群中）积累到一半的 pfail 状态数；
>
> 很显然，这是一个概率问题，简单起见，公式里直接取了一个能在较大概率上保证 fail 判定成立的时间值，10 秒；

因此，上述公式的含义**不是达到这么长时间一定会判定目标节点为 fail，而是经过这么长时间后，集群有很大概率会判定目标节点为 fail** ；

Redis Cluster 默认 `cluster-node-timeout` 为 `15s`，我们将它设置成了 `30s` ，也就是说 700 节点的集群，集群间带宽开销为 `104.5MBit / s`，判定节点失败的时间窗口大概为 `55s` ；

> 实际上，大多数情况下都小于 55s，因为上边的计算都是按照高位时间估算的；

总而言之，对于规模较大的 Redis 集群，cluster-node-timeout 参数值的调整需要谨慎；



### 控制主节点写命令传播

Redis 中 master 节点的每个写命令都会传播到以下三个地方：

- 本地 AOF 文件，以持久化持数据；
- master 节点下所有 slave 节点，以保持主从数据同步；
- 本节点的 repl_backlog 缓存（复制缓冲区），主要为了支持部分同步功能（[partial resynchronization](http://redis.io/topics/replication)）；


#### 减少从节点的数量

- 高可用集群不应该出现单点，所以 Redis 集群一般都会是**主从模式**；
- Redis 的主从同步机制的实现方式为：需要主节点进行处理的所有写请求，都会同步给其下所有从节点；

> 如果没有从节点，那么对于主节点来说，它只需要处理该请求即可；但对于有 N 个从节点的主节点来说，它还需要的将请求额外传播给 N 个从节点；
> 
>> ⚠️ 这里是对每个写请求都要这样处理；
>

显而易见，**从节点数量对主节点吞吐量的影响是比较大的**；因此我们（线上）采用的是**一主一从模式**；

因为（在当前架构下）从节点不需要再向其它节点同步数据，故生产环境中观察到的主节点 CPU 占用率要比从节点机器高；

#### 关闭 AOF 功能

如果开启 AOF 功能，每个写请求都会 Append 到本地 AOF 文件中，虽然 Linux 中写文件操作会利用到操作系统缓存机制，但是如果关闭 AOF 功能主线程中省去了写 AOF 文件的操作，显然会对吞吐量的增加有帮助；

AOF 是 Redis 的一种持久化方式，**如果关闭了 AOF 功能怎么保证数据的安全性？**我们的做法是：定时在从节点上执行 `BGSAVE` ；当然，具体采用何种策略需要结合具体情况来决定；

#### 去掉频繁的 Cluster nodes 命令

在运维过程中，发现前端请求的平均 RT 增加了大概 50% 左右；研究发现和频繁调用 `cluster nodes` 命令有关；

- 当时集群规模为 500+ 节点，cluster nodes 命令返回的结果大小有 103KB ；
- cluster nodes 命令的调用频率为：每隔 20s 向集群所有节点发送；


### 调优 hz 参数

Redis 会定时做一些任务，任务频率由 hz 参数规定，定时任务主要包含：

- 主动清除过期数据；
- 对数据库进行渐式 Rehash；
- 处理客户端超时；
- 更新请求统计信息；
- 发送集群心跳包；
- 发送主从心跳；

我们没有修改 hz 参数的经验，由于其复杂性，并且在 hz 默认值 10 的情况下，理论上不会对 Redis 吞吐量产生太大影响，建议没有经验的情况下不要修改该参数。

### 参考资料

关于 Redis Cluster 可以参考官方的两篇文档：
- [Redis cluster tutorial](http://www.redis.io/topics/cluster-tutorial) 
- [Redis Cluster specification](http://www.redis.io/topics/cluster-spec)


原文：《[近千节点的Redis Cluster高可用集群案例:优酷蓝鲸优化实战](http://mp.weixin.qq.com/s?__biz=MzAwMDU1MTE1OQ==&mid=2653547585&idx=1&sn=9a664b16f656f757632cd4eb29f9a5dc&scene=21#wechat_redirect)》

 

----------


# 用最少的机器支撑万亿级访问，微博6年Redis优化历程


## 持久化问题

在微博的大多数业务场景中， Redis 是**当做存储**来使用的，因此会开启持久化机制；线上最初采用单机多实例的部署结构，服务器的内存使用率也会比较高。由于官方版本触发 `bgsave` 和 `bgrewriteaof` 操作的时间点是不可控的，依赖于相关的配置项和业务的写入模型，因此**可能会出现单机部署的多个 Redis 实例同时触发 bgsave 或 bgrewriteaof 操作**，这两个操作都是通过 fork 出一个子进程来完成的，由于 copy-on-write 机制，**可能会导致服务器内存很快耗尽， Redis 服务崩溃**。

此外，在磁盘压力较大时（生成 rdb、aof 重写），对 aof 的写入及 fsync 操作可能会出现阻塞，虽然从 2.4 版本开始 fsync 操作调整到 bio 线程来做，主线程 aof 的写入阻塞仍会导致服务阻塞。

> 改进办法：
>> - 单机单实例（降低内存和磁盘 I/O 暴增的概率）；
>> - 考虑将持久化放到从节点上进行（减少 master 受影响的情况）；
>> - 针对单机多实例的场景，如何避免 bgsave 或 bgrewriteaof 的同时发生（定制化改造）；
>> - 定制化调整：
>>> - aof 文件按固定大小滚动；
>>> - 生成 rdb 文件的同时记录当前 aof 的 position ；
>>> - 全量数据由 rdb 和其对应的 aof 文件构成；
>>> - 废弃 aof 重写机制，生成 rdb 后删除无效的 aof 文件；

## 主从同步问题

为了提高服务可用性，避免单点问题，线上业务 Redis 大多采用**主从结构**部署。

官方（较早）版本的主从同步机制，在网络出现问题时（如瞬断），会导致主从重新进行一次全量复制；对单个端口来说，如果数据量小，那么这个影响不大，而如果数据量比较大的话，就会**导致网络流量暴增**，同时 **slave 在加载 rdb 时无法响应任何请求**；

当然官方 2.8 版本支持了 `psync` 增量复制的机制，一定程度上解决了主从连接断开会引发全量复制的问题，但是这种机制**受限于复制积压缓冲区大小**，同时在主库故障需要执行切主操作场景下，主从仍然需要进行全量复制。

> 改进办法：
>> - 借鉴 MySQL 的复制机制，基于 rdb + aof 的方式，自行改造基于 aof positon 的增量复制模式； 


## 冷热数据

- 如何区分和差别对待；
- cache miss 问题；
- LRU 策略；

## 数据迁移问题

- 微博内部建议单端口内存不超过 20GB ；
- 自动迁移？通过工具迁移？
- 实时性和数据均衡性如何保证？



原文：《[用最少的机器支撑万亿级访问，微博6年Redis优化历程](http://mp.weixin.qq.com/s?__biz=MzAwMDU1MTE1OQ==&mid=2653547263&idx=1&sn=fe484b24660b7e1dc4beabca71fe1cb1&scene=21#wechat_redirect)》


----------

# Codis作者黄东旭细说分布式Redis架构设计和踩过的那些坑们


## Redis vs Redis Cluster vs Codis

### Redis

- 单点问题；
      - 基于 master-slave 模式解决；
      - 基于 proxy 解决；
      - 基于 Redis Cluster 解决；
- 单点内存容量问题；
      - 基于 proxy 解决；
      - 基于 Redis Cluster 解决；
- 水平扩展问题；
      - 基于 Twemproxy 实现静态分布式：扩容/缩容对运维要求非常高，很难做到平滑的扩缩容；
      - 基于 Codis 实现数据迁移和扩容/缩容功能，同时兼容 Twemproxy 的功能； 


### Redis Cluster

劣势：
- 数据存储模块和分布式逻辑模块耦合在一起，理论上存在升级上的困难（换句话说，如果不存在升级问题的话……）；
- 对协议进行了较大的修改，对客户端不太友好（我觉得只有对存在历史包袱的业务才有问题）；

优势：
- 部署简单；
- 动态扩容/缩容；


### Codis

![Codis Architecture](https://github.com/moooofly/ImageCache/blob/master/Pictures/codis%20architecture.png "Codis Architecture")

结构：
- 实现了分布式逻辑的、无状态的 proxy 层；
- 数据分布状态存储于 zookeeper 或 etcd 中；
- 底层的存储引擎默认为 Redis ，但实现了可插拔；

> ⚠️ proxy 层提供的分布式逻辑应该理解为针对访问请求的 hash 分发；

优势：
- proxy 层和 Redis 存储层可以动态水平扩展；
- 可以基于冷热状态对数据分布进行分组，并通过 zk + proxy 的策略将 client 路由到不同的分组进行访问；
- 基于冷热状态分组的数据可以使用不同存储引擎进行存储；
- 支持采用 hashtag 的方式将特定 key 分布到指定机器上（这个是 twemproxy 引入的语法）；

劣势：
- 需要对 Redis 版本做一些小 patch ；
- 需要依赖 zookeeper 或 etcd ；
- 增加 proxy 导致多了一次网络交互，性能会有所下降；
- 不支持读写分离（官方理由：不能容忍数据不一致问题）；
- 存在数据丢失可能（同 Redis 主从复制情况）；
- 虽然支持 MGET/MSET ，但无法保证原本单点时的原子语义（因为所参与的 key 可能分不在不同的机器上）；
- 支持基于 lua 脚本扩展 Redis 功能的方式，但仅提供转发功能，并不保证脚本操作的数据是否在正确的节点上（若 lua 脚本涉及多个 key 访问，需要业务自行保证所有 key 都位于同一台机器上）；

> ⚠️ 在 proxy 可以动态扩展的情况下，整个服务的 QPS 并不由单个 proxy 的性能决定。


## Codis 下一步改进

### 在 proxy 内集成 Raft 以代替外部的 Zookeeper
将用于同步路由信息的、强一致算法放到 proxy 内部，移除外部依赖；

> 吐槽：难道这不会面临和 Redis Cluster 一样的升级困难问题么？

### 抽象存储引擎层

- 通过自动化的 agent 或直接基于 proxy 启动和管理存储引擎的生命周期；
- 在 proxy 内部集成存储引擎，以便最大程度上的减小 Proxy 转发的损耗；

> 吐槽：proxy 内集成存储引擎？！直接说成重新开发个分布式数据库多直接～～

### replication based migration
目前 Codis 的数据迁移方式是通过修改底层 Redis（就是前面说的小 patch），带来了以下的问题：
- 速度比较慢；
- 对 Redis 有侵入性；
- 维护 slot 信息给 Redis 带来额外的内存开销；


## Codis 在使用中会遇到的问题

### Codis 强依赖的 zookeeper

因此 zk 本身会遇到的问题都会转嫁给 Codis ，容易导致服务不可用；

### 两层 HA

针对 Redis 层 HA 提供了一个能够将 server group 中的 slave 提升为新的 master 的小工具：[这里](ttps://github.com/ngaut/codis-ha)；

###  基于 dashboard 进行集群信息变更

- dashboard 会对外暴露一系列 RESTful API 接口；
- 请保证 dashboard 和其他各个组件的网络连通性；

### 关于 master-slave 和 bgsave

- codis 本身并不负责维护 Redis 的主从关系；
- proxy 只会将请求打到 master 上，master 挂了 codis-ha 会将某一个 slave 提升成 master ；
- 建议 master 不要开 bgsave ，也不要轻易执行 save 命令，数据备份尽量放在 slave 上操作；


### 关于跨机房/多活问题

- codis 没有多副本的概念；

### 关于 proxy 的部署位置问题

- 理论上讲，应该将 proxy 部署在离 client 很近的地方，比如同一个物理机上，这样有利于减少延迟；

## 关于 Codis 的 Q&A

### Codis 没有多副本概念，请问是什么意思？

- 通过 presharding 方式把数据分成 1024 份（每台物理机负责若干份），然后通过 proxy 将不同的 key 请求转发到不同的机器上；
- 数据的副本是通过 Redis 本身 master-slave 机制保证的；

### zookeeper 在 Codis 中的作用是？

- 存储路由信息；
- 作为事件同步的媒介（比如变更 master 或者数据迁移）；

### Codis 的数据分片是用的一致性 hash 吗？

不是，采用的是 presharding 方式，hash 算法为 crc32(key) % 1024 ；

### 针对跨机房有什么方案？

Codis 定位是同一个机房内部的缓存服务，跨机房复制对于 Redis 这样的服务来说，存在以下问题
- 延迟较大；
- 一致性难以保证；
- 对于性能要求比较高的缓存服务，跨机房使用不是最佳实践；

### Codis 本身没有多租户概念，也没有做到高可用，那么设计目标是？

Codis 主要解决的是 
- Redis 单点问题；
- 业务不停的情况下，怎么动态的水平扩展；


### Codis 中冷数据的处理方式？

完整的 Redis sync 协议 ＋ [rocksdb](https://github.com/reborndb/qdb) 存储引擎 = 支持磁盘存储的 slave；


### 若 redis 实例在内存占比超过 50% 后执行 bgsave ，在开启虚拟内存支持时会阻塞，不开启虚拟内存支持时会直接返回 error，对吗？

不一定，实际情况取决于写数据的频繁程度（开启 bgsave 后修改的数据）；

Redis 内部执行 bgsave 实际上是基于操作系统 COW 机制来实现复制，如果在触发 bgsave 的时间段内，几乎所有数据都被修改了，才会导致操作系统只能完整复制全部内存内容，才会导致内存爆掉；


原文：《[Codis作者黄东旭细说分布式Redis架构设计和踩过的那些坑们](http://mp.weixin.qq.com/s?__biz=MzAwMDU1MTE1OQ==&mid=208733458&idx=1&sn=691bfde670fb2dd649685723f7358fea&scene=21#wechat_redirect)》
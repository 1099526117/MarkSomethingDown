# 2016年12月02日 线上 zookeeper 异常情况问题纪要

标签（空格分隔）： zookeeper

---

一句话总结：这次会议针对 zookeeper 事件进行了回顾，并将可能问题点进行了罗列，并给出了一些后续改进方案；

## 可能问题点

1. 办公网络变更（据说变更后 qcr 到办公网延迟变大，办公室到 xg 则正常）；
2. 腾讯云本身存在一些问题（在 pps 打高后，同属 c 网段的两个相邻 ip 地址互 ping 延迟高达 100ms 以上；而一般情况下，互 ping 也有 8ms；据说目前使用单队列，最高 pps 在 60000 左右）
3. 应用发布无自检（导致xxxx）；
4. zk 的 outstanding request 队列飙高；

## 后续解决方案

1. 建立新灾备；
2. 去除跨机房 zk 集群的使用（目前应该 xg 和 qcr 中的 zk 构成了一个大集群）
3. 在 应用 和 zk 之间增加 gateway 进行定制化处理（限流，检测异常连接等）
4. 应用自检脚本应该会提升为价值观；
5. zk 扩容（解决 outstanding request 队列飙高问题）
6. 在 qcr 重现 zk 问题
7. 完善发布工具（制定 checklist 或提供检测脚本）

## 对 sre 提出了点期待（尚未明确说明）

1. 在出问题时，能够进行系统状态留存（没有具体说留存哪些东东）
2. 异常网络流量重放（希望能够将异常情况下的网络流量抓下来，后续用于重放，当然也可以采用其它实现手段）

## 未提及的问题

1. 在网络延迟达到 100ms 的情况下，zk 集群是否存在脑裂问题（zk 的配置是否能够容忍 100ms 的延时问题）
2. python 的进程管理程序在判定 worker 进程在 30s 内未能从 zk 上将配置全部拉取成功后，会将 worker 进程杀死，但没有说明杀死的方式，以及 socket 的处理，不知道是否会对 zk 造成影响；




